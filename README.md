
**PuMba** (**P**rotein-protein interface eval**u**ation with Vision **M**am**ba**) is a deep learning-based scoring function for protein-protein docking, designed to distinguish native-like from non-native conformations. It is an improvement of **PIsToN** [(Stebliankin et al., 2023)](https://www.nature.com/articles/s42256-023-00715-4), by replacing the Vision Transformer backbone of PIsToN with Vision Mamba, resulting in enhanced predictive accuracy while preserving explainability.


**Pretrained Model**  
The pretrained model is provided in the [savedModels] [savedModels](https://github.com/Azam-Shi/PuMba/tree/main/savedModels) directory.  

**Training and Validation Data**  
Lists of training and validation sets are available in the `data` directory.  

**Preprocessing Scripts**  
Scripts for preprocessing input data can be found at [link-to-preprocessing-scripts].  

**Training Example**  
An example training script is provided at [link-to-training-example].  
